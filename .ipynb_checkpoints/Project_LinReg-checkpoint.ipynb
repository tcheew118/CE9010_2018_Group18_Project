{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# math library\n",
    "import numpy as np\n",
    "\n",
    "# visualization library\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 3d visualization\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "#import k-fold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('zscore_data.txt', delimiter=';')\n",
    "\n",
    "# number of training data\n",
    "n = data.shape[0] #YOUR CODE HERE\n",
    "print(n)\n",
    "\n",
    "#select the train data and test data\n",
    "idx = np.random.permutation(range(n))\n",
    "idx_test = idx[:271]\n",
    "idx_train = idx[271:1471]\n",
    "#print(idx_train)\n",
    "#print(len(idx_train))\n",
    "#print(len(idx_test))\n",
    "train_data = data[idx_train,:]\n",
    "test_data = data[idx_test, :]\n",
    "\n",
    "#input the data, X\n",
    "X = np.ones([1200, 2])\n",
    "X [:, 0] = train_data[:, 0]\n",
    "X [:, 1] = train_data[:, 1]\n",
    "#print(X.shape)\n",
    "\n",
    "#input y\n",
    "y = np.ones([1200, 1])\n",
    "y [:, 0] = train_data[:, 2]\n",
    "#print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the predictive function\n",
    "def pred_f (X, w):\n",
    "    y_pred = X.dot(w)\n",
    "    return y_pred\n",
    "#print(pred_f(X,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the loss function\n",
    "def loss_reg(w,X,y,reg): \n",
    "    n = len(y)\n",
    "    w = w.squeeze()[:,None]\n",
    "    y_pred = pred_f(X,w)\n",
    "    loss = 1/n* (y_pred - y).T.dot(y_pred - y) \n",
    "    d = w.shape[0]\n",
    "    loss += reg/d * w.T.dot(w)\n",
    "    return loss\n",
    "#print(mse_f(X, w, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute optimum w_solution\n",
    "def compute_w_solution(X,y,reg):  #the method to determine w by minimizing the loss\n",
    "    initial_w = np.zeros((X.shape[1],1))\n",
    "    result = minimize(loss_reg, initial_w, args=(X,y,reg), method='Powell', options={'maxiter':100})\n",
    "    w_solution = np.array(result.x)[:,None]\n",
    "    loss_solution = loss_reg(w_solution,X,y,reg)\n",
    "    return w_solution, loss_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw graph determine hyper-parameter\n",
    "def loss_plot (hyper_para, loss_tab):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "   # Generate the values\n",
    "    x_vals = hyper_para[:, 0]\n",
    "    y_vals = hyper_para[:, 1]\n",
    "    z_vals = loss_tab\n",
    "\n",
    "   # Plot the values\n",
    "    ax.scatter(x_vals, y_vals, z_vals, c = 'b', marker='o')\n",
    "    ax.set_xlabel('d, learning capacity')\n",
    "    ax.set_ylabel('reg, regularization parameter')\n",
    "    ax.set_zlabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.]\n",
      " [  2.   0.]\n",
      " [  3.   0.]\n",
      " ..., \n",
      " [  8.  10.]\n",
      " [  9.  10.]\n",
      " [ 10.  10.]]\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "#create a mesh grid\n",
    "list_d = list(range(1,11))\n",
    "m1, m2 = np.meshgrid(list_d, np.linspace(0,10,100)) # create meshgrid\n",
    "hyper_para = np.ones([np.prod(m1.shape),2]) \n",
    "hyper_para[:,0] = m1.reshape(-1)\n",
    "hyper_para[:,1] = m2.reshape(-1)\n",
    "print(hyper_para)\n",
    "print(hyper_para.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the optimum hyper-parameter, by K-fold\n",
    "kf = KFold(n_splits=4)\n",
    "train_loss_tab = np.zeros(hyper_para.shape[0])\n",
    "val_loss_tab = np.zeros(hyper_para.shape[0])\n",
    "mean_loss_tab = np.zeros(hyper_para.shape[0])\n",
    "for train_index,test_index in kf.split(X):\n",
    "        #print(\"Train Index:\",train_index,\",Test Index:\",test_index)\n",
    "        train_X, val_X = X[train_index],X[test_index]\n",
    "        train_y, val_y = y[train_index],y[test_index]\n",
    "        for i in range(hyper_para.shape[0]):\n",
    "            d = int(hyper_para[i, 0])\n",
    "            poly = PolynomialFeatures(d)\n",
    "            train_X_poly = poly.fit_transform(train_X)\n",
    "            train_w_solution, train_loss_solution = compute_w_solution(train_X_poly,train_y,hyper_para[i, 1])\n",
    "            train_loss_tab[i] = train_loss_tab[i] + train_loss_solution\n",
    "            val_X_poly = poly.fit_transform(val_X)\n",
    "            val_loss = loss_reg(train_w_solution,val_X_poly,val_y,hyper_para[i, 1])\n",
    "            val_loss_tab[i] = val_loss_tab[i] + val_loss\n",
    "            mean_loss_tab[i] = mean_loss_tab[i] + train_loss_tab[i] + val_loss_tab[i]\n",
    "train_loss_tab = train_loss_tab/4\n",
    "val_loss_tab = val_loss_tab/4\n",
    "mean_loss_tab = mean_loss_tab/4\n",
    "loss_plot (hyper_para, train_loss_tab)\n",
    "loss_plot (hyper_para, val_loss_tab)\n",
    "loss_plot (hyper_para, mean_loss_tab)\n",
    "print(mean_loss_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
